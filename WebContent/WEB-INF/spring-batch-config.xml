<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns:batch="http://www.springframework.org/schema/batch"
	xmlns:task="http://www.springframework.org/schema/task"
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns:p="http://www.springframework.org/schema/p"
	xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.1.xsd http://www.springframework.org/schema/batch http://www.springframework.org/schema/batch/spring-batch-3.0.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-4.1.xsd">

    <context:annotation-config />
    <context:component-scan base-package="jobs" />

	<task:annotation-driven executor="batchTaskExecutor" scheduler="scheduling" exception-handler="myAsyncUncaughtExceptionHandler" />

	<bean id="myAsyncUncaughtExceptionHandler" class="exceptions.MyAsyncUncaughtExceptionHandler" />

	<!-- By default when specifying @Async on a method, the executor that will be used is the one supplied to the 'annotation-driven' -->
	<!-- the value attribute of the @Async annotation can be used when needing to indicate that an executor other than the default should be used -->
	<!-- set up a default executor -->
	<!-- <task:executor id="batchTaskExecutor" pool-size="7" queue-capacity="10" rejection-policy="CALLER_RUNS" keep-alive="3600" /> -->
	<task:executor id="batchTaskExecutor" pool-size="03" queue-capacity="05" rejection-policy="CALLER_RUNS" keep-alive="3600" />
	<!-- <task:executor id="executorWithPoolSizeRange" pool-size="5-25" queue-capacity="100" rejection-policy="DISCARD" keep-alive="3600" /> -->
	<task:scheduler id="scheduling" pool-size="03" />

	<task:scheduled-tasks scheduler="scheduling">
		<!-- new CronTrigger("* 15 9-17 * * MON-FRI") -->
		<!-- java.lang.IllegalArgumentException: Cron expression must consist of 6 fields (found 7 in "0 00 0 1 APR,MAY,JUN ? 2018") -->

		<!-- <task:scheduled ref="jobs" method="run_database_maintenance" cron="0 30 01 ? * *"  /> -->
  		<!-- <task:scheduled ref="jobs" method="run_pam" cron="0 41 11 ? * *" /> -->
  		<task:scheduled ref="jobs" method="run_pam" cron="30 01 00 ? * *" />

  		<task:scheduled ref="jobs" method="renew_crbt" cron="0 30 02 ? * *" />
  		<!-- <task:scheduled ref="jobs" method="run_pam" cron="00 30 01 ? * *" /> -->

		<task:scheduled ref="jobs" method="setHappyBirthdayBonus" cron="0 30 07 ? * *" />

  		<!-- <task:scheduled ref="jobs" method="clear_ussd" fixed-delay="900000" /> -->
  		<task:scheduled ref="jobs" method="clear_ussd" fixed-delay="720000" />
	</task:scheduled-tasks>

    <bean id="transactionManager" class="org.springframework.batch.support.transaction.ResourcelessTransactionManager" />
    <bean id="jobRepository" class="org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean" p:transactionManager-ref="transactionManager" />
    <bean id="jobLauncher" class="org.springframework.batch.core.launch.support.SimpleJobLauncher" p:jobRepository-ref="jobRepository" p:taskExecutor-ref="batchTaskExecutor" />
 	<!-- <bean id="jobLauncher" class="org.springframework.batch.core.launch.support.SimpleJobLauncher" p:jobRepository-ref="jobRepository">
	  	<property name="taskExecutor">
	    	<bean class="org.springframework.core.task.SimpleAsyncTaskExecutor" />
	  	</property>
  	</bean> -->

	<batch:job id="cleanExpiredUssdRequestJob">
	  <batch:step id="cleanUssdRequest">
	  	<!-- <batch:tasklet ref="cleanExpiredUssdRequestTasklet" transaction-manager="transactionManager" /> -->
	  	<batch:tasklet transaction-manager="transactionManager">
          <bean class="jobs.CleanExpiredUssdRequestTasklet">
     		<property name="productProperties" ref="productProperties" />
     		<property name="dao" ref="dao" />
     	  </bean>
	  	</batch:tasklet>
	  </batch:step>
	</batch:job>

	<batch:job id="runningPAMJob">
	  <batch:listeners>
      	<!-- <batch:listener>
          <bean class="jobs.listeners.JobPhaseEventListener" />
        </batch:listener> -->
        <batch:listener ref="jobPhaseEventListener" />
  	  </batch:listeners>

	  <batch:step id="runningPAM">
	  	<!-- throttle-limit, this attribute configures the level of thread concurrency and has a default value of 4 -->
	  	<!-- Ensure the core pool size is larger than this limit. -->
	  	<!-- <batch:tasklet task-executor="MultithreadedStepsTaskExecutor" throttle-limit="5"> -->
	  	<batch:tasklet task-executor="MultithreadedStepsTaskExecutor" throttle-limit="4">
	  	<!-- <batch:tasklet> -->
	      <!-- <batch:chunk reader="subscribers" processor="runningPAMProcessor" writer="runningPAMWriter" commit-interval="100" /> -->
	      <!-- <batch:chunk reader="subscribers" processor="runningPAMProcessor" writer="runningPAMWriter" commit-interval="50" /> -->
	      <!-- <batch:chunk reader="subscribers" processor="runningPAMProcessor" writer="runningPAMWriter" commit-interval="100" skip-limit="10" retry-limit="3"> -->
	      <!-- <batch:chunk reader="subscribers" commit-interval="100" skip-limit="25" retry-limit="3"> -->
	      <batch:chunk reader="runningPAMSubscribers" commit-interval="20" skip-limit="20" retry-limit="3">

	        <batch:processor>
	          <bean class="jobs.RunningPAMProcessor">
      			<property name="waitingForResponse" value="false" />
      			<property name="productProperties" ref="productProperties" />
      		  </bean>
	        </batch:processor>

	        <batch:writer>
	          <bean class="jobs.RunningPAMWriter">
	          	<property name="dao" ref="dao" />
	          </bean>
	        </batch:writer>

			<!-- The Step allows a limit for the number of times an exception can be skipped, and a list of exceptions that are 'skippable'. -->
         	<batch:skippable-exception-classes>
            	<batch:include class="exceptions.AirAvailabilityException" />

            	<!-- <batch:include class="org.springframework.batch.item.file.FlatFileParseException" />
            	<batch:exclude class="java.lang.Exception" />
            	<batch:exclude class="java.io.FileNotFoundException" /> -->
         	</batch:skippable-exception-classes>

			<!-- The Step allows a limit for the number of times an individual item can be retried, and a list of exceptions that are 'retryable'. -->
	        <batch:retryable-exception-classes>
	          	<batch:include class="org.springframework.dao.DeadlockLoserDataAccessException"/>
	        </batch:retryable-exception-classes>
	      </batch:chunk>

		  <!-- the Step can be configured with a list of exceptions that should not cause rollback. -->
	      <batch:no-rollback-exception-classes>
	         <batch:include class="java.lang.Throwable" />
	      </batch:no-rollback-exception-classes>

		  <!-- Intercepting Step Execution -->
		  <!-- Just as with the Job, there are many events during the execution of a Step where a user may need to perform some functionality.
		  This can be accomplished with one of many Step scoped listeners. -->
    	  <batch:listeners>
    	  	<batch:listener ref="jobRunListener" />

      		<batch:listener>
      			<bean class="jobs.listeners.StagingRunningPAMStepListener" scope="step">
      				<property name="dao" ref="dao" />
      				<property name="productProperties" ref="productProperties" />
      			</bean>
      		</batch:listener>

      		<batch:listener>
      			<bean class="jobs.listeners.StagingRunningPAMChunkUpdater" scope="step" />
      		</batch:listener>

			<batch:listener ref="itemProcessingSkipListener" />
    	  </batch:listeners>
	    </batch:tasklet>

		<!-- Declares job should end at this point, without the possibility of restart. BatchStatus will be COMPLETED. ExitStatus is configurable. -->
		<!-- The 'end' element instructs a Job to stop with a BatchStatus of COMPLETED. A Job that has finished with status COMPLETED cannot be restarted (the framework will throw a JobInstanceAlreadyCompleteException) -->
		<!-- The 'end' element also allows for an optional 'exit-code' attribute that can be used to customize the ExitStatus of the Job. If no 'exit-code' attribute is given, then the ExitStatus will be "COMPLETED" by default, to match the BatchStatus. -->
    	<!-- <batch:end on="FAILED" /> -->
    	<!-- <batch:end on="COMPLETED WITH SKIPS" to="errorPrint1" /> -->

		<!-- Declares job should fail at this point. BatchStatus will be FAILED. ExitStatus is configurable. -->
		<!-- The 'fail' element instructs a Job to stop with a BatchStatus of FAILED. Unlike the 'end' element, the 'fail' element will not prevent the Job from being restarted.
		The 'fail' element also allows for an optional 'exit-code' attribute that can be used to customize the ExitStatus of the Job. If no 'exit-code' attribute is given, then the ExitStatus will be "FAILED" by default, to match the BatchStatus. -->
		<!-- <batch:fail on="FAILED" exit-code="EARLY TERMINATION" /> -->

		<!-- Declares job should be stop at this point and provides pointer where execution should continue when the job is restarted. -->
		<!-- The 'stop' element instructs a Job to stop with a BatchStatus of STOPPED. Stopping a Job can provide a temporary break in processing so that the operator can take some action before restarting the Job. -->
		<!-- The 'stop' element requires a 'restart' attribute that specifies the step where execution should pick up when the Job is restarted. -->
		<!-- <batch:stop on="COMPLETED" restart="step2" /> -->

		<!-- If transition elements are used, then all of the behavior for the Step's transitions must be defined explicitly. While there is no limit to the number of transition elements on a Step, if the Step's execution results in an ExitStatus that is not covered by an element, then the framework will throw an exception and the Job will fail. The framework will automatically order transitions from most specific to least specific. -->
		<!-- Defines a transition from this step to the next one depending on the value of the exit status. ExitStatus represents the status of a Step after it finishes execution. More specifically, the 'next' element above references the exit code of the ExitStatus -->
    	<!-- <batch:next on="COMPLETED WITH SKIPS" to="errorPrint1" /> -->
    	<!-- <batch:next on="*" to="step2" /> -->
    	<batch:next on="COMPLETED" to="nightAdvantagesNotificationThroughSms" />
	  </batch:step>

	  <batch:step id="nightAdvantagesNotificationThroughSms">
	  	<batch:tasklet task-executor="MultithreadedStepsTaskExecutor" throttle-limit="4">
	      <!-- <batch:chunk commit-interval="100" skip-limit="20" retry-limit="3"> -->
	      <batch:chunk commit-interval="50" skip-limit="20" retry-limit="3">
	        <batch:reader>
				<bean class="jobs.SynchronizingNightAdvantagesSubscriberReader">
				  <property name="delegate">
			  		<!-- reader must be evaluated for every scheduled execution of the given job. -->
			  		<!-- If you set the scope of the bean to step, then a new bean will be created every time the step is executed. -->
					<!-- <bean class="org.springframework.batch.item.database.JdbcCursorItemReader" scope="step"> -->
					<bean class="jobs.NightAdvantagesSubscriberReader" scope="step">
					  	<property name="dataSource" ref="db_connection" />
					  	<!-- <property name="sql">
					  		<value>
					    		SELECT ID,MSISDN,FLAG,CRBT,LAST_UPDATE_TIME,CRBT_NEXT_RENEWAL_DATE,LOCKED FROM MTN_KIF_MSISDN_EBA WHERE ((FLAG = 1) AND (LOCKED = 0))
					    		SELECT ID,MSISDN,FLAG,CRBT,LAST_UPDATE_TIME,CRBT_NEXT_RENEWAL_DATE,LOCKED FROM MTN_KIF_MSISDN_EBA WHERE FLAG = 1
					  		</value>
					  	</property> -->
					  	<property name="saveState" value="false" />
					  	<property name="rowMapper">
					    	<bean class="dao.mapping.PAMRunningReportingRowMapper" />
					  	</property>
					</bean>
				  </property>
				</bean>
	        </batch:reader>

	        <batch:processor>
	          <bean class="jobs.NightAdvantagesNotificationProcessor">
	          	<property name="dao" ref="dao" />
	          	<property name="productProperties" ref="productProperties" />
	          </bean>
	        </batch:processor>

	        <batch:writer>
	          <bean class="jobs.NightAdvantagesNotificationWriter">
	          	<property name="i18n" ref="messageSource" />
	          	<property name="productProperties" ref="productProperties" />
	          </bean>
	        </batch:writer>

			<!-- The Step allows a limit for the number of times an exception can be skipped, and a list of exceptions that are 'skippable'. -->
         	<batch:skippable-exception-classes>
            	<batch:include class="exceptions.AirAvailabilityException" />

            	<!-- <batch:include class="org.springframework.batch.item.file.FlatFileParseException" />
            	<batch:exclude class="java.lang.Exception" />
            	<batch:exclude class="java.io.FileNotFoundException" /> -->
         	</batch:skippable-exception-classes>

			<!-- The Step allows a limit for the number of times an individual item can be retried, and a list of exceptions that are 'retryable'. -->
	        <batch:retryable-exception-classes>
	          	<batch:include class="org.springframework.dao.DeadlockLoserDataAccessException" />
	        </batch:retryable-exception-classes>
	      </batch:chunk>

		  <!-- the Step can be configured with a list of exceptions that should not cause rollback. -->
	      <batch:no-rollback-exception-classes>
	         <batch:include class="java.lang.Throwable" />
	      </batch:no-rollback-exception-classes>

		  <!-- Intercepting Step Execution -->
		  <!-- Just as with the Job, there are many events during the execution of a Step where a user may need to perform some functionality.
		  This can be accomplished with one of many Step scoped listeners. -->
    	  <batch:listeners>
    	  	<batch:listener ref="jobRunListener" />
			<batch:listener ref="itemProcessingSkipListener" />
    	  </batch:listeners>
	    </batch:tasklet>
	  </batch:step>
	</batch:job>

	<batch:job id="crbtRenewalJob">
	  <batch:step id="crbtRenewal">
	  	<!-- <batch:tasklet ref="crbtRenewalTasklet" transaction-manager="transactionManager" /> -->
	  	<batch:tasklet transaction-manager="transactionManager">
          <bean class="jobs.CRBTRenewalTasklet">
          	<property name="i18n" ref="messageSource" />
     		<property name="productProperties" ref="productProperties" />
     		<property name="dao" ref="dao" />
     	  </bean>
		  <!-- Intercepting Step Execution -->
		  <!-- Just as with the Job, there are many events during the execution of a Step where a user may need to perform some functionality.
		  This can be accomplished with one of many Step scoped listeners. -->
    	  <batch:listeners>
    	  	<batch:listener ref="jobRunListener" />
    	  </batch:listeners>
	    </batch:tasklet>
	  </batch:step>
	</batch:job>

	<!-- To disable restart, set the attribute restartable to false on the job element:
	Remember that jobs are restartable by default. If you’re worried that you’ll forget that, set the restartable flag explicitly on all your jobs. -->
	<batch:job id="happyBirthdayBonusJob">
	  <batch:listeners>
      	<!-- <batch:listener>
          <bean class="jobs.listeners.JobPhaseEventListener" />
        </batch:listener> -->
        <batch:listener ref="jobPhaseEventListener" />
  	  </batch:listeners>

	  <!-- A single step cannot have both a "next" attribute and a transition element. -->
	  <!-- <batch:step id="stepA" next="stepB" /> -->
	  <batch:step id="happyBirthdayBonus">
	  	<!-- <batch:tasklet task-executor="MultithreadedStepsTaskExecutor" throttle-limit="5"> -->
	  	<batch:tasklet task-executor="MultithreadedStepsTaskExecutor" throttle-limit="4">
	      <!-- <batch:chunk reader="allMTNKIFSubscribersWithNoHappyBirthDayBonusReader" processor="happyBirthdayBonusProcessor" writer="happyBirthdayBonusWriter" commit-interval="10" skip-limit="20" retry-limit="3"> -->
	      <batch:chunk reader="allMTNKIFSubscribersWithNoHappyBirthDayBonusReader" commit-interval="10" skip-limit="20" retry-limit="3">

	        <batch:processor>
	          <bean class="jobs.HappyBirthdayBonusProcessor">
	          	<property name="dao" ref="dao" />
	          	<property name="productProperties" ref="productProperties" />
	          </bean>
	        </batch:processor>

	        <batch:writer>
	          <bean class="jobs.HappyBirthdayBonusWriter">
	          	<property name="i18n" ref="messageSource" />
	          	<property name="productProperties" ref="productProperties" />
	          </bean>
	        </batch:writer>

			<!-- Each stream element involved in the step.
			By default, objects referenced using a reader, processor, and writer are automatically registered. You don’t need to specify them again here. -->
	        <!-- <batch:streams>
	          <batch:stream ref="allHVCsWithNoBonusReader" />
	          <batch:stream ref="defaultBonusWriter" />
	        </batch:streams> -->

			<!-- The Step allows a limit for the number of times an exception can be skipped, and a list of exceptions that are 'skippable'. -->
         	<batch:skippable-exception-classes>
            	<batch:include class="exceptions.AirAvailabilityException" />

            	<!-- <batch:include class="org.springframework.batch.item.file.FlatFileParseException" />
            	<batch:exclude class="java.lang.Exception" />
            	<batch:exclude class="java.io.FileNotFoundException" /> -->
         	</batch:skippable-exception-classes>

			<!-- The Step allows a limit for the number of times an individual item can be retried, and a list of exceptions that are 'retryable'. -->
	        <batch:retryable-exception-classes>
	          	<batch:include class="org.springframework.dao.DeadlockLoserDataAccessException"/>
	        </batch:retryable-exception-classes>
	      </batch:chunk>

		  <!-- the Step can be configured with a list of exceptions that should not cause rollback. -->
	      <batch:no-rollback-exception-classes>
	         <batch:include class="java.lang.Throwable" />
	      </batch:no-rollback-exception-classes>

		  <!-- Intercepting Step Execution -->
		  <!-- Just as with the Job, there are many events during the execution of a Step where a user may need to perform some functionality.
		  This can be accomplished with one of many Step scoped listeners. -->
    	  <batch:listeners>
    	  	<batch:listener ref="jobRunListener" />

      		<batch:listener>
      			<bean class="jobs.listeners.StagingHappyBirthDayBonusSubscriberStepListener" scope="step">
      				<property name="dao" ref="dao" />
      				<property name="productProperties" ref="productProperties" />
      			</bean>
      		</batch:listener>

      		<batch:listener>
      			<bean class="jobs.listeners.StagingHappyBirthDayBonusProcessedSubscriberChunkUpdater" scope="step" />
      		</batch:listener>

      		<batch:listener ref="itemProcessingSkipListener" />
    	  </batch:listeners>
	    </batch:tasklet>

		<!-- Declares job should end at this point, without the possibility of restart. BatchStatus will be COMPLETED. ExitStatus is configurable. -->
		<!-- The 'end' element instructs a Job to stop with a BatchStatus of COMPLETED. A Job that has finished with status COMPLETED cannot be restarted (the framework will throw a JobInstanceAlreadyCompleteException) -->
		<!-- The 'end' element also allows for an optional 'exit-code' attribute that can be used to customize the ExitStatus of the Job. If no 'exit-code' attribute is given, then the ExitStatus will be "COMPLETED" by default, to match the BatchStatus. -->
    	<!-- <batch:end on="FAILED" /> -->
    	<!-- <batch:end on="COMPLETED WITH SKIPS" to="errorPrint1" /> -->

		<!-- Declares job should fail at this point. BatchStatus will be FAILED. ExitStatus is configurable. -->
		<!-- The 'fail' element instructs a Job to stop with a BatchStatus of FAILED. Unlike the 'end' element, the 'fail' element will not prevent the Job from being restarted.
		The 'fail' element also allows for an optional 'exit-code' attribute that can be used to customize the ExitStatus of the Job. If no 'exit-code' attribute is given, then the ExitStatus will be "FAILED" by default, to match the BatchStatus. -->
		<!-- <batch:fail on="FAILED" exit-code="EARLY TERMINATION" /> -->

		<!-- Declares job should be stop at this point and provides pointer where execution should continue when the job is restarted. -->
		<!-- The 'stop' element instructs a Job to stop with a BatchStatus of STOPPED. Stopping a Job can provide a temporary break in processing so that the operator can take some action before restarting the Job. -->
		<!-- The 'stop' element requires a 'restart' attribute that specifies the step where execution should pick up when the Job is restarted. -->
		<!-- <batch:stop on="COMPLETED" restart="step2" /> -->

		<!-- If transition elements are used, then all of the behavior for the Step's transitions must be defined explicitly. While there is no limit to the number of transition elements on a Step, if the Step's execution results in an ExitStatus that is not covered by an element, then the framework will throw an exception and the Job will fail. The framework will automatically order transitions from most specific to least specific. -->
		<!-- Defines a transition from this step to the next one depending on the value of the exit status. ExitStatus represents the status of a Step after it finishes execution. More specifically, the 'next' element above references the exit code of the ExitStatus -->
    	<!-- <batch:next on="COMPLETED WITH SKIPS" to="errorPrint1" /> -->
    	<!-- <batch:next on="*" to="step2" /> -->
	  </batch:step>
	</batch:job>

	<!-- Job scope, introduced in Spring Batch 3.0 is similar to Step scope in configuration but is a Scope for the Job context so there is only one instance of such a bean per executing job.
	Additionally, support is provided for late binding of references accessible from the JobContext using #{..} placeholders. Using this feature, bean properties can be pulled from the job or job execution context and the job parameters. -->
	<!-- Because it is not part of the Spring container by default, the scope must be added explicitly, either by using the batch namespace:
	Or by including a bean definition explicitly for the JobScope <bean class="org.springframework.batch.core.scope.JobScope" /> (but not both): -->
	<bean id="jobPhaseEventListener" class="jobs.listeners.JobPhaseEventListener" scope="job">
		<property name="productProperties" ref="productProperties" />

    	<!-- <property name="name" value="#{jobParameters[input]}" /> -->
    	<!-- <property name="name" value="#{jobExecutionContext['input.name']}.txt" /> -->
	</bean>

	<!-- Using a scope of Step is required in order to use late binding since the bean cannot actually be instantiated until the Step starts, which allows the attributes to be found.
	Because it is not part of the Spring container by default, the scope must be added explicitly, either by using the batch namespace:
	or by including a bean definition explicitly for the StepScope <bean class="org.springframework.batch.core.scope.StepScope" /> (but not both): -->
    <bean id="jobRunListener" class="jobs.listeners.JobRunListener" scope="step">
      	<property name="dao" ref="dao" />
      	<property name="productProperties" ref="productProperties" />

      	<!-- <property name="resource" value="#{stepExecutionContext['input.file.name']}" />
      	<property name="resource" value="#{jobExecutionContext['input.file.name']}" /> -->
    </bean>

	<bean id="itemProcessingSkipListener" class="jobs.listeners.ItemProcessingSkipListener" scope="step" />

	<!-- Configuring a thread-safe JdbcCursorItemReader with an indicator -->
	<!-- You start by configuring a SynchronizingItemReader bean to make the delegate item reader thread-safe. The synchronized item reader uses the delegate property to reference the delegate item reader.
	You then use the processed indicator column in the SQL statement to read data. A processed value of false causes the database to return only unprocessed rows.
	Finally, you  disable Spring Batch state management. This is the other requirement to make the item reader thread-safe (with the synchronization of the read method).
	But by doing that, you lose the reader’s restartability feature, because the item reader won’t know where it left off after a failure.
	Luckily, the process indicator is there to enable restartability: the reader reads only unprocessed items. The item writer then needs to flag the product as handled using the processed column and then write the item, as described in the following listing. -->
	<bean id="allMTNKIFSubscribersWithNoHappyBirthDayBonusReader" class="jobs.SynchronizingBirthDayBonusSubscriberReader">
	  	<property name="delegate">
	  		<!-- reader must be evaluated for every scheduled execution of the given job. -->
	  		<!-- If you set the scope of the bean to step, then a new bean will be created every time the step is executed. -->
			<bean class="jobs.BirthDayBonusSubscribersReader" scope="step">
				<constructor-arg index="0" type="int" value="2" />
		   		<!-- <constructor-arg index="1" type="java.lang.String" value="${AWS_SECRET_ACCESS_KEY}" /> -->

			  	<property name="dataSource" ref="db_connection" />
			  	<property name="saveState" value="false" />
			  	<property name="rowMapper">
			    	<bean class="dao.mapping.BirthDayBonusSubscriberRowMapper" />
			  	</property>
			  	<!-- <property name="sql">
			  		<value>
			    		SELECT ID,MSISDN,NAME,LANGUAGE,BIRTH_DATE,ASPU,BONUS,BONUS_EXPIRES_IN,LAST_UPDATE_TIME FROM MTN_KIF_BIRTHDAY_BONUS_EBA WHERE ((BONUS IS NULL) AND (ASPU IS NOT NULL) AND (LOCKED = 0))
			  		</value>
				</property> -->
			</bean>
	  	</property>
	</bean>

	<!-- Configuring a thread-safe JdbcCursorItemReader with an indicator -->
	<!-- You start by configuring a SynchronizingItemReader bean to make the delegate item reader thread-safe. The synchronized item reader uses the delegate property to reference the delegate item reader.
	You then use the processed indicator column in the SQL statement to read data. A processed value of false causes the database to return only unprocessed rows.
	Finally, you  disable Spring Batch state management. This is the other requirement to make the item reader thread-safe (with the synchronization of the read method).
	But by doing that, you lose the reader’s restartability feature, because the item reader won’t know where it left off after a failure.
	Luckily, the process indicator is there to enable restartability: the reader reads only unprocessed items. The item writer then needs to flag the product as handled using the processed column and then write the item, as described in the following listing. -->
	<bean id="runningPAMSubscribers" class="jobs.SynchronizingSubscriberReader">
	  <property name="delegate">
  		<!-- reader must be evaluated for every scheduled execution of the given job. -->
  		<!-- If you set the scope of the bean to step, then a new bean will be created every time the step is executed. -->
		<!-- <bean class="org.springframework.batch.item.database.JdbcCursorItemReader" scope="step"> -->
		<bean class="jobs.RunningPAMSubscriberReader" scope="step">
			<constructor-arg index="0" type="int" value="0" />
			<!-- <constructor-arg index="0" type="int" value="1" /> -->

		  	<property name="dataSource" ref="db_connection" />
		  	<!-- <property name="sql">
		  		<value>
		    		SELECT ID,MSISDN,FLAG,CRBT,LAST_UPDATE_TIME,CRBT_NEXT_RENEWAL_DATE,LOCKED FROM MTN_KIF_MSISDN_EBA WHERE ((FLAG = 1) AND (LOCKED = 0))
		    		SELECT ID,MSISDN,FLAG,CRBT,LAST_UPDATE_TIME,CRBT_NEXT_RENEWAL_DATE,LOCKED FROM MTN_KIF_MSISDN_EBA WHERE FLAG = 1
		  		</value>
		  	</property> -->
		  	<property name="saveState" value="false" />
		  	<property name="rowMapper">
		    	<bean class="dao.mapping.SubscriberRowMapper" />
		  	</property>
		</bean>
	  </property>
	</bean>

	<!-- The configurable "task-executor" attribute is used to specify which TaskExecutor implementation should be used to execute the individual flows. The default is SyncTaskExecutor, but an asynchronous TaskExecutor is required to run the steps in parallel. Note that the job will ensure that every flow in the split completes before aggregating the exit statuses and transitioning. -->
	<!-- <bean id="ParallelStepsTaskExecutor" class="org.springframework.core.task.SimpleAsyncTaskExecutor">
	  Spring creates a threadpool of 10 threads, executing each chunk in a different thread or 10 chunks in parallel
	  <property name="concurrencyLimit" value="10" />
	  <property name="concurrencyLimit" value="3" />
	</bean> -->

	<!-- <task:executor id="executorWithCallerRunsPolicy" pool-size="5-25" queue-capacity="100" rejection-policy="CALLER_RUNS" /> -->
	<!-- <task:executor id="MultithreadedStepsTaskExecutor" pool-size="10" queue-capacity="25" rejection-policy="CALLER_RUNS" keep-alive="1800" /> -->
	<!-- <task:executor id="MultithreadedStepsTaskExecutor" pool-size="5-10" queue-capacity="25" rejection-policy="CALLER_RUNS" keep-alive="3600" /> -->

	<!-- <task:executor id="MultithreadedStepsTaskExecutor" pool-size="5-10" queue-capacity="25" rejection-policy="CALLER_RUNS" keep-alive="1800" /> -->
	<task:executor id="MultithreadedStepsTaskExecutor" pool-size="4-7" queue-capacity="20" rejection-policy="CALLER_RUNS" keep-alive="1800" />

	<!-- <bean id="MultithreadedStepsTaskExecutor" class="org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor">
	    <property name="corePoolSize" value="5" />
	    <property name="maxPoolSize" value="10" />
	    <property name="queueCapacity" value="25" />
	</bean> -->
	<!-- <bean id="MultithreadedStepsTaskExecutor" class="org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor">
  		<property name="corePoolSize" value="5" />
  		<property name="maxPoolSize" value="5" />
	</bean> -->

</beans>